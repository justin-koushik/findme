{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3ibc_v35U7wj"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from random import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-JRJ48ADVrNj"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torchvision.transforms.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Of8_svobj0De"
      },
      "outputs": [],
      "source": [
        "device='cuda'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6_gwy94CWE1T"
      },
      "outputs": [],
      "source": [
        "parentPath='/content/drive/MyDrive/me/'\n",
        "positivePath=parentPath+'parsedme/'\n",
        "negativePath=parentPath+'parsednotme/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7UYXbpY5U2vf"
      },
      "outputs": [],
      "source": [
        "def resizeImg(imgPath):\n",
        "    temp=F.pil_to_tensor(Image.open(imgPath).resize((128,128))).to(dtype=torch.float32)\n",
        "    mean=torch.mean(temp)\n",
        "    std=torch.std(temp)\n",
        "    return F.normalize(temp,mean=mean,std=std).to(device=device)\n",
        "\n",
        "def getData():\n",
        "    positiveFiles=[positivePath+path for path in os.listdir(positivePath)]\n",
        "    shuffle(positiveFiles)\n",
        "    negativeFiles=[negativePath+path for path in os.listdir(negativePath)]\n",
        "    shuffle(negativeFiles)\n",
        "\n",
        "    trainposData=map(resizeImg,positiveFiles[:150])\n",
        "    trainnegData=map(resizeImg,negativeFiles[:150])\n",
        "    testposData=map(resizeImg,positiveFiles[150:175])\n",
        "    testnegData=map(resizeImg,negativeFiles[150:175])\n",
        "\n",
        "    trainposlabel=torch.ones((150,1)).to(device)\n",
        "    trainneglabel=torch.zeros((150,1)).to(device)\n",
        "    testposlabel=torch.ones((25,1)).to(device)\n",
        "    testneglabel=torch.zeros((25,1)).to(device)\n",
        "\n",
        "    trainData = list(zip(trainposData,trainposlabel)) +   list(zip(trainnegData,trainneglabel))\n",
        "    testData  = list(zip(testposData,testposlabel))   +   list(zip(testnegData,testneglabel))\n",
        "    shuffle(trainData)\n",
        "    shuffle(testData)\n",
        "\n",
        "    return trainData,testData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "aXM_dysqXO1X"
      },
      "outputs": [],
      "source": [
        "trainData,testData=getData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KA8HmbAzks51"
      },
      "outputs": [],
      "source": [
        "class myassistant(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(myassistant,self).__init__()\n",
        "    self.conv1=nn.Conv2d(3,16,3)\n",
        "    self.pool1=nn.MaxPool2d(2)\n",
        "    self.conv2=nn.Conv2d(16,16,3)\n",
        "    self.pool2=nn.MaxPool2d(2)\n",
        "    self.lin1=nn.Linear(16*30*30,128)\n",
        "    self.lin2=nn.Linear(128,1)\n",
        "  def forward(self,x):\n",
        "    x=nn.functional.relu(self.conv1(x))\n",
        "    x=self.pool1(x)\n",
        "    x=nn.functional.relu(self.conv2(x))\n",
        "    x=self.pool2(x)\n",
        "    x=x.flatten()\n",
        "    x=nn.functional.relu(self.lin1(x))\n",
        "    x=torch.sigmoid(self.lin2(x))\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hL2uFjNwlvB6"
      },
      "outputs": [],
      "source": [
        "model=myassistant().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "7JxDexIKpEpx"
      },
      "outputs": [],
      "source": [
        "lossFunc=nn.BCELoss()\n",
        "optimizer=SGD(model.parameters(),lr=0.0002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z084MVgGldHC",
        "outputId": "ec822f04-51f4-48da-efdd-8413905957da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 - 60.0764274597168\n",
            "epoch 1 - 43.35356521606445\n",
            "epoch 2 - 32.1224365234375\n",
            "epoch 3 - 24.453786849975586\n",
            "epoch 4 - 19.11665916442871\n",
            "epoch 5 - 15.31724739074707\n",
            "epoch 6 - 12.551822662353516\n",
            "epoch 7 - 10.488265991210938\n",
            "epoch 8 - 8.911184310913086\n",
            "epoch 9 - 7.68127965927124\n",
            "epoch 10 - 6.701298236846924\n",
            "epoch 11 - 5.906935691833496\n",
            "epoch 12 - 5.255220413208008\n",
            "epoch 13 - 4.711631774902344\n",
            "epoch 14 - 4.252938747406006\n",
            "epoch 15 - 3.8625636100769043\n",
            "epoch 16 - 3.528038501739502\n",
            "epoch 17 - 3.237978458404541\n",
            "epoch 18 - 2.9847402572631836\n",
            "epoch 19 - 2.762519598007202\n",
            "epoch 20 - 2.5673673152923584\n",
            "epoch 21 - 2.39363956451416\n",
            "epoch 22 - 2.2383508682250977\n",
            "epoch 23 - 2.0995194911956787\n",
            "epoch 24 - 1.9739031791687012\n",
            "epoch 25 - 1.861520767211914\n",
            "epoch 26 - 1.7587531805038452\n",
            "epoch 27 - 1.6654003858566284\n",
            "epoch 28 - 1.5797561407089233\n",
            "epoch 29 - 1.502052903175354\n"
          ]
        }
      ],
      "source": [
        "for i in range(30):\n",
        "  totalLoss=0\n",
        "  for img,label in trainData:\n",
        "      pred=model(img)\n",
        "      optimizer.zero_grad()\n",
        "      loss=lossFunc(pred,label)\n",
        "      totalLoss+=loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "  print(f'epoch {i} - {totalLoss}')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYerU7oxr7yo",
        "outputId": "b6b63839-57c7-485a-9b28-e6576d8b0ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47\n"
          ]
        }
      ],
      "source": [
        "#testing accuracy\n",
        "with torch.no_grad():\n",
        "  total=0\n",
        "  for img,label in testData:\n",
        "    pred=model(img)\n",
        "    total+=(round(pred.item())==label.item())\n",
        "print(total)# total 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "myassistant(\n",
              "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (lin1): Linear(in_features=14400, out_features=128, bias=True)\n",
              "  (lin2): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tmodel=myassistant()\n",
        "tmodel.load_state_dict(torch.load('model.pt',map_location=torch.device('cpu')))\n",
        "tmodel.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Gc5vjHR19cy"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "if not cap.isOpened():\n",
        "    print(\"Cannot open camera\")\n",
        "    exit()\n",
        "while True:\n",
        "    try:\n",
        "        ret, frame = cap.read()\n",
        "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "        if not ret:\n",
        "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
        "            break\n",
        "        faces=face_cascade.detectMultiScale(gray,1.05,5)\n",
        "        for face in faces:\n",
        "            x,y,w,h=face\n",
        "            parsed=frame[y:y+h,x:x+w,:]\n",
        "            pilImage=Image.fromarray(parsed).resize((128,128))\n",
        "            tensor=F.pil_to_tensor(pilImage).to(dtype=torch.float32)\n",
        "            mean=tensor.mean()\n",
        "            std=tensor.std()\n",
        "            tensor=F.normalize(tensor,mean=mean,std=std)\n",
        "            with torch.no_grad():\n",
        "                pred=tmodel(tensor)\n",
        "                if pred>0.9:\n",
        "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,255),2)\n",
        "        cv2.imshow('cam',frame)\n",
        "        k = cv2.waitKey(30) & 0xff\n",
        "        if k == 27:\n",
        "            break\n",
        "    except ValueError:\n",
        "        break\n",
        "plt.imshow(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "c6775f008c80a58a24d6fb73f82cc5d490f68df26e158b11540769a2968c169d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
